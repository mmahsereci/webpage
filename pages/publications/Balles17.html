<div class="pub-img"><img style="margin-bottom: 6em;" src="./../assets/img/publications/Balles17.png"></div>

**Automating Stochastic Optimization with Gradient Variance Estimates**<br>
One reason optimization methods might have to expose free parameters to the user, rather
than to set them internally, is that these parameters are not identifiable given the “observations”
available to the method. We discuss the use of gradient variance estimates
as an additional source of information allowing for automation of stochastic optimization
algorithms. We review several recent results that use such estimates to eliminate (i.e.,
determine internally, without user intervention) hyper-parameters of stochastic optimizers
and contribute a detailed discussion of the efficient implementation of gradient variance
estimates for neural networks.
<br>
*Lukas Balles, Maren Mahsereci, Philipp Hennig* AutoML Workshop, ICML 2017.

<div class="pub-ul"><ul>
    <li><a class="button-pub" href="https://7bce9816-a-62cb3a1a-s-sites.googlegroups.com/site/automl2017icml/accepted-papers/AutoML_2017_paper_6.pdf?attachauth=ANoY7cq6kv_KSergf07tEvRAgtMZxioI5VJzpW0RCbX73jdWHIJi9UVTpkLufRzx8cgpYUi3rrrvT6gNHohQ7dHZv6duOYUjrPSNSDK_EpskgjtOxAA4nlEY48Sy2v_QsfEaFatZmdXfP-M43RzAWEE4rB8qq5sE-Q0mfA89auEEeHknxHbcsqPjX_zi8bDI_oEs5XpzDZsUpw8tK9FvKsPRixHMUEaQR3Yvj1NVk9yWcPua7gzBIcsebE8DGhnRhDZ-NC2-4Onu&attredirects=0"><p>Paper</p></a></li>
    <li><a class="button-pub" onclick="CollapseBibTeX('Balles17')"><p>BibTeX</p></a></li>
</ul></div>

<div class="pub-bib" id="Balles17">
  <blockquote>
    <div class="div-name">@article{Balles17,
        <div class="div-info">
          author = {Balles, Lukas and Mahsereci, Maren and Hennig, Philipp},<br>
          title = {Automating Stochastic Optimization with Gradient Variance Estimates},<br>
          booktitle = {AutoML Worlshop, ICML},<br>
          year = {2017}
        </div>
      }
   </div>
  </blockquote>
</div>
